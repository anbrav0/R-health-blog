[
  {
    "objectID": "GLM_for_count.html",
    "href": "GLM_for_count.html",
    "title": "Genalized Linear Model: Using Count Data",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(katex)"
  },
  {
    "objectID": "GLM_for_count.html#introduction",
    "href": "GLM_for_count.html#introduction",
    "title": "Genalized Linear Model: Using Count Data",
    "section": "2 Introduction",
    "text": "2 Introduction\nIn this presentation, we will be discussing how to use the Generalized Linear Model (GLM) method using count data in the R programming language. We will show how to clean and wrangle the data, show necessary columns to execute our method, discuss assumptions held, showcase the code used to run this GLM, and the interpretation of our output results."
  },
  {
    "objectID": "GLM_for_count.html#what-is-a-glm",
    "href": "GLM_for_count.html#what-is-a-glm",
    "title": "Genalized Linear Model: Using Count Data",
    "section": "3 What is a GLM?",
    "text": "3 What is a GLM?\n\n3.1 lets start with a quick overview of the simple linear regression\nAs you know, a simple linear regression has two major components: a Y, dependent outcome and an X, which is your independent or your predictor variable. the model looks something like this:\nE(Y|X) = \\beta_0 + \\beta_1 where \\beta_0 is your intercept and \\beta_1 is your slope. A linear model is a function, that us used to fit a data. We often use this method to see the association, or strength in association between two variables of interest:\n\n\nCode\n# load data:\ndata(trees)\n\n#rename variables:\nnames(trees) <- c(\"DBH_in\",\"height_ft\", \"volume_ft3\")\n\n# simple model:\nmodel <- lm(DBH_in ~ height_ft, data = trees)\n\n# plot:\nsimple_trees <-\n  #data\n  ggplot(data = trees) +\n  \n  # x and y\n  aes(x = height_ft, y = DBH_in) + \n  \n  #labels\n  labs(title = \"Example of Simple Association - Using Trees Data\",\n       x = \"Height in feet\",\n       y = \"Diameter in inches\") + \n  \n  # add points\n  geom_point() + \n  \n  # add the lm\n  geom_smooth(method = \"lm\", color = \"blue\", se = FALSE) +\n  \n  # add a simple theme\n  theme_bw()\n\n# actual plot: \nsimple_trees\n\n\n\n\n\nOften you will find this model writen in this form:\n E(Y|X) = \\beta_0 + \\beta_1 + \\varepsilon where \\beta_0 and \\beta_1 are our coefficients that need to be estimated and $ $ used for more complex lines Our goal is to see the association between an outcome with an exposure.\n\n\n3.2 Assumptions of a linear question\nBefore diving into the generalized models, lets quickly overview the assumptions of linear regression.\n\nAssumption 1: for each combination of independent variable x, y is a random variable with a certain probability distribution.\nAssumption 2: Y values are statistical dependent.\nAssumption 3: the mean value of Y, for each specific combination of values of X, is a linear function.\nAssumption 4: the variance of Y, is the same for any fixed value of X_n\nAssumption 5: for any fixed combination of X_n, Y is normally distributed.\n\nSomething to note, that in the simple explanation above we are assuming our Y variable (remember one of the points we talked above above? that y holds a specific distribution!) is continuous. So lets talk about our Y variable having a count distribution.\n\n\n3.3 lets talk about the generalized linear model\nthe term “generalized” is a big umbrella term used to describe a large class of models. Our response variable y_i is following an exponential family distribution with a mean of u_i which is sometimes non-linear! However McCallagh and Nelder considered them to be linear because our covariate affect the distribution of y_i only through linear combination.\nthere are three major components of a GLM:\n\nA Random component: which specifies the probability distribution of our response variable\nSystematic component: specifies the explanatory variable (x_1 .. x_n) in our model. Or their linear combination (\\beta_0 + \\beta_1) etc.\na link function: specifies the LINK between the random and systematic components. This helps us figure out our expected values of the response is related to the linear combination of our explanatory variables. for example the link function g(u) = u, which is called an identity function. this models the mean directly. Or, in the case we will talk about today the log of the mean:\n\n log(\\pmb{\\mu}) = \\alpha + \\beta_1x_1 + ... B_nx_n + \\epsilon\n\n\n3.4 What is a Poisson Regression?\na Poisson regression models how the mean of a discrete (or we can say count too!) response variable Y depends on our explanatory X variables. Here is a simple look at the Poisson regression:\n  log \\lambda_i = \\beta_0 + \\beta x_i  where the random component: the distribution of Y is the mean of \\lambda and the systematic component is the explanatory variable (or your X variables, which can be continuous or categorical) that is linearly associated. Or can be transformed if non-linear, and the link function is the log link stated in the section above (link the section number here?)\nAn advantage of using GLM over a normal line model is the link function gives us more flexibility in modeling and this model uses the Maximum likelihood estimate. Additionally we can use different inference tools like Wald’s test for logistic and Poisson models.\n\n\n3.5 important points of Poisson models\n\nwe can use this type of link function by using count data. count data can be describes at the number of devices that can access the internet, number of sex partners you have in your lifetime, and the number of individuals infected with a disease.\nPoisson is unimodel and skewed to the right, both the mean and the variance are the same. In other words, when the count is larger it tends to be more varied.\nif our mew increases the skew decreases and the distribution starts to become more bell shapped. our mean tends to look something like this:\n\n\\pmb{\\mu} = exp(\\alpha + \\beta x) = e^\\alpha (e^\\beta)^x  where one unit increase in X has a multiplicative impact on your e^\\beta power on the mean. (More on this a little later in the interpretation section!)\n\n\n3.6 one last point before we move on\nwhen your modeling count data, the link scale is linear. So the effects are additive on the link. While your response scale is nonlinear (this is on the exponent) and so the effects are multiplicative. makes sense? we will work out an example now!"
  },
  {
    "objectID": "GLM_for_count.html#example-1-using-glm-for-count-responses---crab-data",
    "href": "GLM_for_count.html#example-1-using-glm-for-count-responses---crab-data",
    "title": "Genalized Linear Model: Using Count Data",
    "section": "4 Example 1: using GLM for count responses - Crab Data",
    "text": "4 Example 1: using GLM for count responses - Crab Data\nLets import the crabs.txt data from the University of Florida’s open-source data files."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Genalized Linear Model: Using Count Data",
    "section": "",
    "text": "Code\nlibrary(katex)\nlibrary(gt)\nlibrary(gtsummary)\nlibrary(devtools)\nlibrary(MEPS)\nlibrary(tidyverse)"
  },
  {
    "objectID": "index.html#introduction",
    "href": "index.html#introduction",
    "title": "Genalized Linear Model: Using Count Data",
    "section": "2 Introduction",
    "text": "2 Introduction\nIn this presentation, we will be discussing how to use the Generalized Linear Model (GLM) method using count data in the R programming language. We will show how to clean and wrangle the data, show necessary columns to execute our method, discuss assumptions held, showcase the code used to run this GLM, and the interpretation of our output results."
  },
  {
    "objectID": "index.html#what-is-a-glm",
    "href": "index.html#what-is-a-glm",
    "title": "Genalized Linear Model: Using Count Data",
    "section": "3 What is a GLM?",
    "text": "3 What is a GLM?\n\n3.1 lets start with a quick overview of the simple linear regression\nAs you know, a simple linear regression has two major components: a Y, dependent outcome and an X, which is your independent or your predictor variable. the model looks something like this:\nE(Y|X) = \\beta_0 + \\beta_1 where \\beta_0 is your intercept and \\beta_1 is your slope. A linear model is a function, that us used to fit a data. We often use this method to see the association, or strength in association between two variables of interest:\n\n\nCode\n# load data:\ndata(trees)\n\n#rename variables:\nnames(trees) <- c(\"DBH_in\",\"height_ft\", \"volume_ft3\")\n\n# simple model:\nmodel <- lm(DBH_in ~ height_ft, data = trees)\n\n# plot:\nsimple_trees <-\n  #data\n  ggplot(data = trees) +\n  \n  # x and y\n  aes(x = height_ft, y = DBH_in) + \n  \n  #labels\n  labs(title = \"Example of Simple Association - Using Trees Data\",\n       x = \"Height in feet\",\n       y = \"Diameter in inches\") + \n  \n  # add points\n  geom_point() + \n  \n  # add the lm\n  geom_smooth(method = \"lm\", color = \"blue\", se = FALSE) +\n  \n  # add a simple theme\n  theme_bw()\n\n# actual plot: \nsimple_trees\n\n\n\n\n\nOften you will find this model writen in this form:\n E(Y|X) = \\beta_0 + \\beta_1 + \\varepsilon where \\beta_0 and \\beta_1 are our coefficients that need to be estimated and \\varepsilon, or the error term, is used for more complex lines. Our goal is to see the association between an outcome with an exposure.\n\n\n3.2 Assumptions of a linear question\nBefore diving into the generalized models, lets quickly overview the assumptions of linear regression.\n\nAssumption 1: for each combination of independent variable x, y is a random variable with a certain probability distribution.\nAssumption 2: Y values are statistical dependent.\nAssumption 3: the mean value of Y, for each specific combination of values of X, is a linear function.\nAssumption 4: the variance of Y, is the same for any fixed value of X_n\nAssumption 5: for any fixed combination of X_n, Y is normally distributed.\n\nSomething to note, that in the simple explanation above we are assuming our Y variable (remember one of the points we talked above above? that y holds a specific distribution!) is continuous. So lets talk about our Y variable having a count distribution.\n\n\n3.3 lets talk about the generalized linear model\nthe term “generalized” is a big umbrella term used to describe a large class of models. Our response variable y_i is following an exponential family distribution with a mean of u_i which is sometimes non-linear! However McCallagh and Nelder considered them to be linear because our covariate affect the distribution of y_i only through linear combination.\nthere are three major components of a GLM:\n\nA Random component: which specifies the probability distribution of our response variable\nSystematic component: specifies the explanatory variable (x_1 .. x_n) in our model. Or their linear combination (\\beta_0 + \\beta_1) etc.\na link function: specifies the LINK between the random and systematic components. This helps us figure out our expected values of the response is related to the linear combination of our explanatory variables. for example the link function g(u) = u, which is called an identity function. this models the mean directly. Or, in the case we will talk about today the log of the mean:\n\n log(\\pmb{\\mu}) = \\alpha + \\beta_1x_1 + ... B_nx_n + \\epsilon\n\n\n3.4 What is a Poisson Regression?\na Poisson regression models how the mean of a discrete (or we can say count too!) response variable Y depends on our explanatory X variables. Here is a simple look at the Poisson regression:\n  log \\lambda_i = \\beta_0 + \\beta x_i  where the random component: the distribution of Y is the mean of \\lambda and the systematic component is the explanatory variable (or your X variables, which can be continuous or categorical) that is linearly associated. Or can be transformed if non-linear, and the link function is the log link stated in the section above (link the section number here?)\nAn advantage of using GLM over a normal line model is the link function gives us more flexibility in modeling and this model uses the Maximum likelihood estimate. Additionally we can use different inference tools like Wald’s test for logistic and Poisson models.\n\n\n3.5 important points of Poisson models\n\nwe can use this type of link function by using count data. count data can be describes at the number of devices that can access the internet, number of sex partners you have in your lifetime, and the number of individuals infected with a disease.\nPoisson is unimodel and skewed to the right, both the mean and the variance are the same. In other words, when the count is larger it tends to be more varied.\nif our mew increases the skew decreases and the distribution starts to become more bell shapped. our mean tends to look something like this:\n\n\\pmb{\\mu} = exp(\\alpha + \\beta x) = e^\\alpha (e^\\beta)^x  where one unit increase in X has a multiplicative impact on your e^\\beta power on the mean. (More on this a little later in the interpretation section!)\n\n\n3.6 A few last points before we move on\nLike with different models in statistics, one must follow the assumptions of a regression, and yes, Poisson has them as well. The assumptions for a Poisson regression are as follows:\n\nYour Y (dependent values) must be count values.\nCount values must have a positive integer (or who numbers) (0, 1, 2, 3, ... k). Negative values will not work here.\nexplanatory variables can be continuous, dichotomous or ordinal\nOur count variable must follow a Poisson distribution that is, the mean and variance should be the same. remember this one!\n\n \\pmb{\\mu} = E(X) = \\lambda    \\sigma^2 = \\lambda \nwhen your modeling count data, the link scale is linear. So the effects are additive on the link. While your response scale is nonlinear (this is on the exponent) and so the effects are multiplicative. makes sense? we will work out an example now!"
  },
  {
    "objectID": "index.html#example-1-using-glm-for-count-responses---using-the-meps-data-set-for-2020",
    "href": "index.html#example-1-using-glm-for-count-responses---using-the-meps-data-set-for-2020",
    "title": "Genalized Linear Model: Using Count Data",
    "section": "4 Example 1: using GLM for count responses - Using the MEPS data set for 2020",
    "text": "4 Example 1: using GLM for count responses - Using the MEPS data set for 2020\nLets import the built in National Health Care Survery data set from the Medical Expenditure Panel Survey website located here. the code book can also be located here for the 2020 Full year Consolidate data file.\n\n4.1 import MEPS data set\n\n\nCode\n# clean \nHC2020_clean <- read_csv(\"/Users/anbravo/GitHub/R-health-blog/HC2020_clean.csv\")\n\n# Load data from AHRQ MEPS website\nhc2020 = read_MEPS(file = \"h224\")\n\n# lets name a copy of this data set so i don't ruin it\nhc2020_2 <- hc2020\n\n# these variables are upper case, lets turn them lower case\nnames(hc2020_2) <- tolower(names(hc2020_2))\n\n# theres about 14,000 variables. lets keep the ones we want to look at\nhc2020_subset <- hc2020_2 |> \n  select(dupersid,obdrv20, ertot20, rthlth31, adpain42, region31, age20x, racev1x, sex, marry31x, educyr, faminc20, empst31, mcare20)\n\n\n\n# cleaning names:--------------------------------------------------------------\n# dupersid = Person ID\n# obdrv20 = number of office based physician visits in 2020 \n# ertot20 = emergency rooms visits in 2020\n# rthlth31 = perceived health status \n# adpain41 = pain level \n# region31 = Census region: Northest, midwest, south and west \n# age20x = Age as of Dec 2020\n# racev1x = race: white, black, American indiain, Asian, multiple races \n# sex = sex at birth \n# marry31x = marital status\n# educyr = year of ed when entered in MEPS\n# faminc20 = family total income \n# empst31 = employment status \n# mcare20 = Covered by medicare? Yes/no \n\n# removing old names because that sub header in columns messes me up sometimes ---\n\nnames(hc2020_subset) <- NULL\n\n\nnew_names <- c(\"Person_ID\",\n               \"Nubr_office_visits\",\n               \"Nubr_emergency_visits\",\n               \"Health_status\",\n               \"Pain_Level\",\n               \"Region\",\n               \"Age_as_Dec2020\",\n               \"Race\",\n               \"Is_male\",\n               \"Is_married\",\n               \"Education_lvl\",\n               \"Total_fam_incom\",\n               \"Is_employed\",\n               \"Covered_by_MediCar\")\n\n\nnames(hc2020_subset) <- new_names\n\n\n# this data set has codes for NA, will switch to NA in R ------------------------\n\nHC2020_clean <- HC2020_clean |> \n  mutate(Pain_Level = na_if(Pain_Level, -15)) |>\n  mutate(Health_status = na_if(Health_status, -8)) |>\n  mutate(Region = na_if(Region, -1)) |> \n  mutate(Age_as_Dec2020 = na_if(Age_as_Dec2020, -1)) |>\n  mutate(Is_married = na_if(Is_married,-8 )) |> \n  mutate(Is_employed = na_if(Is_employed, -15)) |> \n  mutate(Education_lvl = na_if(Education_lvl, -15)) |> \n  mutate(Covered_by_MediCar = na_if(Covered_by_MediCar, -1))\n  \n  \n# also, for ease of interpretation i will dichotomize some variables ------------\n\n\n HC2020_clean <- HC2020_clean |> \n  mutate(Is_married = ifelse(Is_married == 1, 1, 0)) |> \n  mutate(Is_employed = ifelse(Is_employed == 1, 1, 0)) |> \n  mutate(Is_male = ifelse(Is_male == 1 , 1, 0 )) |> \n  mutate(Covered_by_MediCar = ifelse(Covered_by_MediCar == 1, 1, 0))\n\n\n\n# i also want to transform some variable using case when -----------------------\n\nHC2020_clean <- HC2020_clean |> \n  mutate(Health_status = case_when(\n    Health_status == 1 ~ \"Good\",\n    Health_status == 2 ~ \"Good\",\n    Health_status == 3 ~ \"Fair\",\n    Health_status == 4 ~ \"Fair\",\n    Health_status == 5 ~ \"Poor\"\n    )) \n\n# i want to write CSV this data set for later use --------------------------------\n\nwrite_csv(hc2020_subset,\n          file = \"/Users/anbravo/GitHub/R-health-blog/HC2020_clean.csv\")\n\n\nlet’s say i want to take a sneak peak at this data set. I will use the gtsummary package to look at the first levels of the data set, and I just want to very simply make this data set interactive by using the opt_interactive() function in the gt package.\n\n\nCode\nHC2020_clean |> \n  select(Person_ID, Nubr_office_visits, Health_status, Pain_Level, Region, Is_employed, Is_married, Is_employed) |> \n  #head(10) |> \n  gt() |> \n  \n  tab_header(\n    title = \"Brief view of HC 2020 data set\",\n    subtitle = \"2020 Data from MEPS website\"\n  ) |> \n  \n opt_interactive(\n   use_search = TRUE,\n   use_highlight = TRUE, \n   use_compact_mode = TRUE,\n   use_resizers = TRUE,\n   use_text_wrapping = FALSE,\n   pagination_type = \"jump\"\n   )\n\n\n\n\n\n\nBrief view of HC 2020 data set\n2020 Data from MEPS website"
  },
  {
    "objectID": "index.html#some-quick-data-exploration",
    "href": "index.html#some-quick-data-exploration",
    "title": "Genalized Linear Model: Using Count Data",
    "section": "5 Some quick data exploration",
    "text": "5 Some quick data exploration\nRemember what I said earlier about the mean and variance being the same? EDA is important because it might tell us more details about our variable of interest. For this particular question, we might be interested in the number of times an event has occurred. In this case, the number of times someone pay a visit to an office doctor. This data follows everyone for exactly one year.\n\nI am interested in seeing the number of physician office visits in the last year (we can also call this our Y variable)\nWe are interested in seeing how self-perceived health status (Good, Fair, or Poor), gender (is male, 1 = male, 0 = female), and marital status (married = 0, not married/other categories = 0) is associated with number of doctor visits (our X variables).\n\nBecause we are looking at count data, we might find it important to check out the mean and variance of our Y variables. In the case that our Y variable mean and variance are not the same, we might consider some sort of transformation. Transforming a data set can help with the normality of it.\n\n5.1 lets look at the outcome variable of interest\n\n\nCode\nmean(HC2020_clean$Nubr_office_visits, na.rm = TRUE)\n\n\n[1] 2.792591\n\n\nthe mean of this data set is about 2.79.\n\n\nCode\nvar(HC2020_clean$Nubr_office_visits, na.rm = TRUE)\n\n\n[1] 34.58851\n\n\nand the variance is about 34.59. We might need to do something with this particular data set but as an example, lets first run a Generalized Linear Model without doing any kind of transformation to the data."
  },
  {
    "objectID": "index.html#how-to-build-a-glm-with-a-poisson-distribution",
    "href": "index.html#how-to-build-a-glm-with-a-poisson-distribution",
    "title": "Genalized Linear Model: Using Count Data",
    "section": "6 How to build a GLM with a Poisson Distribution",
    "text": "6 How to build a GLM with a Poisson Distribution\nThe basic core functions of a GLM look something like this: glm(counts ~ outcome + treatment, data = data_set, family = poisson() which includes:\n\ncounts: would be your Y variable\ndata: where your pulling the data from\n~: or an equal sign\noutcome + treatment: are your X variables\nfamily: the link or distribution you are following\n\nWe are interested in measuring number of visits to a doctors office as a function of perceived health, sex assigned at birth, and marital status.\n\n# build first model \nPossionModel1 <- glm(Nubr_office_visits ~ Health_status + Is_male + Is_married, \n                     data = HC2020_clean, family = \"poisson\")\n\n# check summary \nsummary(PossionModel1)\n\n\nCall:\nglm(formula = Nubr_office_visits ~ Health_status + Is_male + \n    Is_married, family = \"poisson\", data = HC2020_clean)\n\nDeviance Residuals: \n   Min      1Q  Median      3Q     Max  \n-4.575  -2.069  -1.227   0.310  34.409  \n\nCoefficients:\n                   Estimate Std. Error z value Pr(>|z|)    \n(Intercept)        1.340582   0.006745  198.76   <2e-16 ***\nHealth_statusGood -0.579132   0.007486  -77.37   <2e-16 ***\nHealth_statusPoor  0.749656   0.014752   50.82   <2e-16 ***\nIs_male           -0.296143   0.007366  -40.20   <2e-16 ***\nIs_married         0.258006   0.007280   35.44   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 164561  on 27182  degrees of freedom\nResidual deviance: 151166  on 27178  degrees of freedom\n  (622 observations deleted due to missingness)\nAIC: 199315\n\nNumber of Fisher Scoring iterations: 6\n\n\nthis summary gives us the null deviance, which is the total sum of squares, and the residual deviance which is the sum of square errors or the unexplained deviance. We also get the AIC for this model (although AIC is more useful when comparing to other model fits) and we also get the model coefficients for Health status, sex assigned at birth, and marital status.\nAdditionally, this output is extremely ugly so we will feed this model into gtsummary in a little bit so looks a little better.\n\n6.1 Modeling with gtsummary"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "Fishersexactest.html",
    "href": "Fishersexactest.html",
    "title": "Fisher’s Exact Test",
    "section": "",
    "text": "Fisher’s exact test is an independent test used to determine if there is a relationship between categorical (non-parametric) variables with a small sample size.\nUsed to assess whether proportions of one variable are different among values of another table.\nUses (hypergeometric) marginal distribution to derive exact p-values which are not approximated which are somewhat conservative.\nThe rules of Chi distribution do not apply when the frequency count is <5 for more than 20% of the cells in a contingency table (Bower 2003).\nData is easily manipulated by using a contingency table.\n\n\n\n\nAssumes that the individual observations are independent.\nAssumes that the row and column totals are fixed or conditioned.\nThe variables are categorical and randomly sampled.\nObservations are count data.\n\n\n\n\nThe hypotheses of Fisher’s exact test are similar to Chi-square test:\nNull hypothesis:(H_0) There is no relationship between the categorical variables, the variables are independent.\nAlternative hypothesis: (H_1) There is a relationship between the categorical variables, the variables are dependent."
  },
  {
    "objectID": "Fishersexactest.html#fishers-exact-test-equation",
    "href": "Fishersexactest.html#fishers-exact-test-equation",
    "title": "Fisher’s Exact Test",
    "section": "Fisher’s Exact Test Equation",
    "text": "Fisher’s Exact Test Equation\nFisher’s exact test for a one-tailed p-value is calculated using the following formula:\n   p = {(a+b)!(c+d)!(a+c)!(b+d)! \\over a! b! c! d! n!} \n\nn = population size/ total frequency\na + b = “successes” values in the contingency table\na + c = sample size / draws from the population\na = sample successes\n\n\nFormula description\nthis test is usually used as a one-tailed test but it can also be used as a two tailed test as well, a,b,c, and d are the individual frequencies on the 2x2 contingency table and n is our total frequency. This particular test is used to obtain the probability of the combination of frequencies that we can actually obtain.\n\n\nWhat is a contingency table?\nThis is a table that shows the distribution of a variable in the rows and columns. Sometimes referred to as a 2x2 table. They are useful in summarizing categorical variables. The table() function is used to create a contingency table in R. When the variables of interest are summarized in a contingency table it is easier to run the Fisher’s Exact test.\n\nExample: Creating a contingency table\nLets say we have information on the gender of participants in a clinical trial and the type of drug administered to them we can create the following contingency table for further analysis.\n\n\nCode\n# Example R code to create a contingency table\n\n# Creating a data frame\n df = data.frame (\n   \"Drug\" = c(\"Drug A\", \"Drug B\", \"Drug A\"),\n   \"Gender\" = c(\"Male\", \"Male\", \"Female\")\n )\n \n# Creating contingency table using table()\n ctable = table(df)\n print(ctable)\n\n\n        Gender\nDrug     Female Male\n  Drug A      1    1\n  Drug B      0    1\n\n\n\n\n\nPerforming Fisher’s Exact Test in R\nWe will need to install the ggstatplot package to visualize the statistical results.\n\n\nCode\n#install.packages(\"ggstatplot\") \n#install.packages(\"summarytools\")\n#install.packages(\"gmodels\")\n#install.packages(tidyVerse)\n\n\n\n\nData Source: GMP2017\nFor this example we will be using the Greater Manchester Police’s UK stop and search data from 2017(December) sourced from the Sage Research Methods Dataset Part 2. This data has information on stop and search events, gender and ethnicity. For this example we would like to access whether there is a significant relationship between gender and stop and search events?\n\n\nCode\nGMP17 <- read.csv(\"dataset-gmss-2017-subset1.csv\")\n\n\n\n\nLoad in libraries\n\n\nCode\nlibrary(gmodels)\nlibrary(ggstatsplot)\nlibrary(gt)\nlibrary(gtsummary)\nlibrary(katex)\nlibrary(tidyverse)\n\n\n\n\nDescriptive summary\n\nhead(GMP17)\n\n  Gender Ethnicity ObjectSearch\n1      1         1            1\n2      1         1           -9\n3      1         1            1\n4      1         1            1\n5      1         1           -9\n6      1         1            1\n\nstr(GMP17)\n\n'data.frame':   186 obs. of  3 variables:\n $ Gender      : int  1 1 1 1 1 1 1 1 1 -9 ...\n $ Ethnicity   : int  1 1 1 1 1 1 2 1 1 1 ...\n $ ObjectSearch: int  1 -9 1 1 -9 1 1 1 -9 -9 ...\n\n# determining the number of rows\nNROW(GMP17)\n\n[1] 186\n\n\n\n\nAssessing frequencies to answer research question\nFor this analysis we will use the Gender variable and the ObjectSearch variable\n\n\nCode\n# Dropping the Ethnicity variable to remain with variables of interest for for the 2x2 table\n\nnewGMP17 <-GMP17[ -c(2) ]\n \nhead(newGMP17)\n\n\n  Gender ObjectSearch\n1      1            1\n2      1           -9\n3      1            1\n4      1            1\n5      1           -9\n6      1            1\n\n\nThe data contains missing values categorized as -9 that we need to drop and we need to rename our variables based on the data dictionary provided https://methods.sagepub.com/dataset/fishers-exact-gmss-2017-r.\n\n\nCode\n# Exclude rows that have missing data in both variables\nnewGMP17_nom <- subset(newGMP17, Gender > 0)\nnewGMP17_nom2 <- subset(newGMP17_nom, ObjectSearch  > 0)\nsummary(newGMP17_nom2)\n\n\n     Gender       ObjectSearch  \n Min.   :1.000   Min.   :1.000  \n 1st Qu.:1.000   1st Qu.:1.000  \n Median :1.000   Median :1.000  \n Mean   :1.052   Mean   :1.259  \n 3rd Qu.:1.000   3rd Qu.:2.000  \n Max.   :2.000   Max.   :2.000  \n\n\nCode\nnrow(newGMP17_nom2)\n\n\n[1] 116\n\n\n\n\nCode\n# Renaming the Gender variable based on data dictionary\nnewGMP17_nom2$Gender <- \n  recode_factor(\n    newGMP17_nom2$Gender,\n            \"1\" = \"Male\",\n            \"2\" = \"Female\"\n)\n\n# Renaming the Gender variable based on data dictionary\nnewGMP17_nom2$ObjectSearch <- \n  recode_factor(\n    newGMP17_nom2$ObjectSearch,\n            \"1\" = \"Controlled_Drugs\",\n            \"2\" = \"Harmful_Objects\"\n)\n\n\n\n\nCode\n# Creating the contingency table for subset data\ncGMP17 = table(newGMP17_nom2)\nprint(cGMP17)\n\n\n        ObjectSearch\nGender   Controlled_Drugs Harmful_Objects\n  Male                 84              26\n  Female                2               4\n\n\n\n\nVisualizing data using mosaic plot\n\nwe can use the mosaic plot to represent the data.\n\n\n\nCode\nmosaicplot(cGMP17,\n           main ='Mosaic Plot',\n           color = TRUE)\n\n\n\n\n\n\n\nRunning the Fisher’s exact test using fisher.test()\nWhat if we just run a Chi-square test?\nUsing our GMP17 dataset we can try to run a Chi-square test instead of the Fisher’s Exact test and see what happens.\nThe R output gives us a warning that the Chi Square is not appropriate hence we should use another test in this case the Fisher’s Exact Test.\n\n\nCode\nchisq.test(cGMP17)$expected\n\n\nWarning in chisq.test(cGMP17): Chi-squared approximation may be incorrect\n\n\n        ObjectSearch\nGender   Controlled_Drugs Harmful_Objects\n  Male          81.551724       28.448276\n  Female         4.448276        1.551724\n\n\n\n\nRunning the test\n\n\nCode\n# running the fisher's exact test\n\ntest <- fisher.test(cGMP17)\ntest\n\n\n\n    Fisher's Exact Test for Count Data\n\ndata:  cGMP17\np-value = 0.03809\nalternative hypothesis: true odds ratio is not equal to 1\n95 percent confidence interval:\n  0.8528079 73.5937611\nsample estimates:\nodds ratio \n  6.331977 \n\n\nUsing the gt summary to view results.\n\n\nCode\nnewGMP17_nom2 |> \n  tbl_summary(by = Gender) |> \n   add_p() |> \n  add_overall()\n\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      Overall, N = 1161\n      Male, N = 1101\n      Female, N = 61\n      p-value2\n    \n  \n  \n    ObjectSearch\n\n\n\n0.038\n        Controlled_Drugs\n86 (74%)\n84 (76%)\n2 (33%)\n\n        Harmful_Objects\n30 (26%)\n26 (24%)\n4 (67%)\n\n  \n  \n  \n    \n      1 n (%)\n    \n    \n      2 Fisher’s exact test\n    \n  \n\n\n\n\n\n\nInterpretation of results\nThe most important test statistic is the p - value therefore we can retrieve the specific result using the following code;\n\n\nCode\ntest$p.value \n\n\n[1] 0.03808788\n\n\nOdds ratio = 6.33, 95% CI = 0.85-73.59], we reject the null hypothesis (p < 0.05) and conclude that there is a strong association between the two categorical independent variables (gender and object search events)\nTherefore the odds ratio indicates that the odds of getting stopped and searched by gender is 6.33 times as likely for males compared to females. In other words, males are more likely of getting stopped and searched than females.\n\n\nVisualizing statistical results with plots using ggstatsplot\n\nwe download the ggsattsplot package to visualize the results in a plot.\n\n\n\nCode\n# Fisher's exact test \n\ntest <- fisher.test(cGMP17)\n\n# combine plot and statistical test with ggbarstats\n\nggbarstats(\n newGMP17_nom2, Gender, ObjectSearch,\n results.subtitle = FALSE,\n subtitle = paste0(\n \"Fisher's exact test\", \", p-value = \",\n ifelse(test$p.value < 0.001, \"< 0.001\", round(test$p.value, 3))\n  )\n )\n\n\n\n\n\nFrom the plot, it is clear that the proportion of males among object search events is higher compared to females, suggesting that there is a relationship between the two variables.\nThis is confirmed thanks to the p-value displayed in the subtitle of the plot. As previously, we reject the null hypothesis and we conclude that the variables gender and stop and search events are not dependent (p-value = 0.038)."
  },
  {
    "objectID": "Fishersexactest.html#what-if-we-have-more-than-two-levels",
    "href": "Fishersexactest.html#what-if-we-have-more-than-two-levels",
    "title": "Fisher’s Exact Test",
    "section": "What if we have more than two levels?",
    "text": "What if we have more than two levels?\nUsing the drug example used previously lets say we have 3 drugs ‘Drug A, Drug B or Drug C’ and we want to see if there is any relationship with gender ‘Male/Female’.\n\n\nCode\n# Creating a data frame\n df = data.frame (\n   \"Drug\" = c(\"Drug A\", \"Drug B\", \"Drug A\", \"Drug C\", \"Drug C\"),\n   \"Gender\" = c(\"Male\", \"Male\", \"Female\", \"Female\", \"Female\")\n )\n \n# Creating contingency table using table()\n ctable = table(df)\n print(ctable)\n\n\n        Gender\nDrug     Female Male\n  Drug A      1    1\n  Drug B      0    1\n  Drug C      2    0\n\n\n\n\nCode\n# Running the Fisher's Exact test for the 3x2 table\nfisher.test(ctable)\n\n\n\n    Fisher's Exact Test for Count Data\n\ndata:  ctable\np-value = 0.6\nalternative hypothesis: two.sided\n\n\nThe p-value is non-significant [p = 0.6], we fail to reject the null hypothesis (p < 0.05) and conclude that there is no association between the drug treatments and gender. If the results had been significant we would have gone ahead and conducted a pair wise comparison."
  },
  {
    "objectID": "Fishersexactest.html#references",
    "href": "Fishersexactest.html#references",
    "title": "Fisher’s Exact Test",
    "section": "References",
    "text": "References\n\nBower, Keith M. 2003. “When to Use Fisher’s Exact Test.” In American Society for Quality, Six Sigma Forum Magazine, 2:35–37. 4.\nMcCrum-Gardner, Evie. 2008. “Which Is the Correct Statistical Test to Use?” British Journal of Oral and Maxillofacial Surgery 46 (1): 38–41.\nWong KC. Chi squared test versus Fisher’s exact test. Hong Kong Med J. 2011 Oct;17(5):427\nPatil, I. (2021). Visualizations with statistical details: The ‘ggstatsplot’ approach. Journal of Open Source Software, 6(61), 3167, doi:10.21105/joss.03167\nZach Bobbit. (2021). Fisher’s Exact Test: Definition, Formula, and Example\nBobbitt, Z. (2020). “Fisher’s Exact Test: Definition, Formula, and Example.” statology.org"
  }
]